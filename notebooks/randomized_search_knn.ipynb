{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import utils\r\n",
    "import pickle\r\n",
    "import copy\r\n",
    "\r\n",
    "# Plotting utilitys\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Imports for feature engeering\r\n",
    "#from sklearn.decomposition import PCA\r\n",
    "#from sklearn.manifold import TSNE\r\n",
    "\r\n",
    "# Import machine learning librarys\r\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\r\n",
    "from sklearn.metrics import accuracy_score, classification_report\r\n",
    "\r\n",
    "# Import classifiers\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "# Set random state\r\n",
    "np.random.seed(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataset location\r\n",
    "DATASETS = \"./datasets\"\r\n",
    "\r\n",
    "MNIST = \"mnist.hdf5\"\r\n",
    "USPS = \"usps.hdf5\"\r\n",
    "ARDIS = \"ardis.hdf5\"\r\n",
    "\r\n",
    "datasets = {\"ARDIS\": os.path.join(DATASETS, ARDIS), \\\r\n",
    "            \"USPS\": os.path.join(DATASETS, USPS), \\\r\n",
    "            \"MNIST\": os.path.join(DATASETS, MNIST)}\r\n",
    "\r\n",
    "# Load data from hdf5 file and return dict\r\n",
    "data = utils.load_data(datasets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pre_process(X_train, X_test, name, min_max=True, resize=True):\r\n",
    "    \r\n",
    "    if resize:\r\n",
    "        X_train = utils.resize_images(X_train, 16, 16)\r\n",
    "        X_test = utils.resize_images(X_test, 16, 16)\r\n",
    "        \r\n",
    "    if min_max:\r\n",
    "        if name == \"USPS\":\r\n",
    "            X_train  = (X_train + 1.0) / 2.0\r\n",
    "            X_test = (X_test + 1.0) / 2.0\r\n",
    "        else:\r\n",
    "            X_train  = X_train / 255.0\r\n",
    "            X_test = X_test / 255.0\r\n",
    "\r\n",
    "    return X_train, X_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using randomized grid search to find best parameter for KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MODELS = \"./models/randomized_search\"\r\n",
    "use_datasets = [\"ARDIS\", \"USPS\", \"MNIST\"]\r\n",
    "\r\n",
    "kfold = KFold(n_splits=3)\r\n",
    "\r\n",
    "grid_params = {\"n_neighbors\": [2, 4, 6, 8, 10, 12, 14, 16],\r\n",
    "               \"weights\": [\"uniform\", \"distance\"],\r\n",
    "               \"algorithm\": [\"ball_tree\", \"kd_tree\"],\r\n",
    "               \"leaf_size\": [5, 10, 20, 25, 30, 35, 40, 50, 60]\r\n",
    "              }\r\n",
    "\r\n",
    "for dataset_name in use_datasets:\r\n",
    "    print(f\"Using dataset: {dataset_name}\")\r\n",
    "    \r\n",
    "    # Select data\r\n",
    "    X_train, X_test, y_train, y_test = copy.deepcopy(utils.select_dataset(data, dataset_name))\r\n",
    "    \r\n",
    "    # Resize and scale\r\n",
    "    X_train, X_test = pre_process(X_train, X_test, dataset_name)\r\n",
    "    \r\n",
    "    # Alogrithem for optimization\r\n",
    "    model = KNeighborsClassifier()\r\n",
    "    \r\n",
    "    search = RandomizedSearchCV(model,\r\n",
    "                                grid_params,\r\n",
    "                                n_iter=60,\r\n",
    "                                cv=kfold,\r\n",
    "                                scoring='accuracy',\r\n",
    "                                verbose=10,\r\n",
    "                                random_state=3,\r\n",
    "                                n_jobs=-1)\r\n",
    "    \r\n",
    "    search.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    # Predict on training- and testset\r\n",
    "    pred_train = search.predict(X_train)\r\n",
    "    pred_test = search.predict(X_test)\r\n",
    "        \r\n",
    "    # Calculate error rate\r\n",
    "    train_error_rate = (1.0 - accuracy_score(pred_train, y_train)) * 100\r\n",
    "    test_error_rate = (1.0 - accuracy_score(pred_test, y_test)) * 100\r\n",
    "    \r\n",
    "    # Print Results\r\n",
    "    print(f\"Best estimator: {search.best_estimator_}\")\r\n",
    "    print(f\"Best params: {search.best_params_}\")\r\n",
    "    print(f\"Best score: {search.best_score_}\")\r\n",
    "    print(\"KNN train error: {:.3f}%\".format(train_error_rate))\r\n",
    "    print(\"KNN test error: {:.3f}%\".format(test_error_rate))\r\n",
    "                   \r\n",
    "    # Pickel model for later inspection                \r\n",
    "    pickle_string = f\"{dataset_name.lower()}-KNN-{train_error_rate:.3f}-{test_error_rate:.3f}-model.pickle\"\r\n",
    "    pickle_path = os.path.join(MODELS, pickle_string)\r\n",
    "    pickle.dump(search, open(pickle_path, 'wb'))\r\n",
    "    \r\n",
    "    print(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}