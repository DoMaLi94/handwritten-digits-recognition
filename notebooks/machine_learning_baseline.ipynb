{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import utils\r\n",
    "import copy\r\n",
    "\r\n",
    "# Plotting utilitys\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Imports for feature engeering\r\n",
    "#from sklearn.decomposition import PCA\r\n",
    "#from sklearn.manifold import TSNE\r\n",
    "\r\n",
    "# Import machine learning librarys\r\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\r\n",
    "from sklearn.metrics import accuracy_score, classification_report\r\n",
    "\r\n",
    "# Import classifiers\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "#from sklearn.neural_network import MLPClassifier\r\n",
    "\r\n",
    "# Pipeline building\r\n",
    "#from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "# Set random state\r\n",
    "np.random.seed(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def pre_process(X_train, X_test, dataset_name, min_max=True, resize=True):\r\n",
    "    \r\n",
    "    if resize:\r\n",
    "        # Resize using CV2 and linear function\r\n",
    "        X_train = utils.resize_images(X_train, 16, 16)\r\n",
    "        X_test = utils.resize_images(X_test, 16, 16)\r\n",
    "        \r\n",
    "    if min_max:\r\n",
    "        # Normalize data between 0 and 1 on a dataset level\r\n",
    "        if dataset_name == \"USPS\":\r\n",
    "            X_train  = (X_train + 1.0) / 2.0\r\n",
    "            X_test = (X_test + 1.0) / 2.0\r\n",
    "        else:\r\n",
    "            X_train  = X_train / 255.0\r\n",
    "            X_test = X_test / 255.0\r\n",
    "\r\n",
    "    return X_train, X_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Dataset location\r\n",
    "DATASETS = \"./datasets\"\r\n",
    "\r\n",
    "MNIST = \"mnist.hdf5\"\r\n",
    "USPS = \"usps.hdf5\"\r\n",
    "ARDIS = \"ardis.hdf5\"\r\n",
    "\r\n",
    "datasets = {\"ARDIS\": os.path.join(DATASETS, ARDIS), \\\r\n",
    "            \"USPS\": os.path.join(DATASETS, USPS), \\\r\n",
    "            \"MNIST\": os.path.join(DATASETS, MNIST)}\r\n",
    "\r\n",
    "# Load data from hdf5 file and return dict\r\n",
    "data = utils.load_data(datasets)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading ARDIS...\n",
      "Loading USPS...\n",
      "Loading MNIST...\n",
      "Done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train models for a baseline without optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "for dataset_name in [\"USPS\", \"ARDIS\",\"MNIST\"]:\r\n",
    "    print(f\"Using dataset: {dataset_name}\")\r\n",
    "    \r\n",
    "    # Select data\r\n",
    "    X_train, X_test, y_train, y_test = copy.deepcopy(utils.select_dataset(data, dataset_name))\r\n",
    "    \r\n",
    "    X_train, X_test = pre_process(X_train, X_test, dataset_name)\r\n",
    "    \r\n",
    "    models = [\r\n",
    "        (\"GNB\", GaussianNB()),\r\n",
    "        (\"KNN\", KNeighborsClassifier(n_jobs=-1)),\r\n",
    "        (\"LR\", LogisticRegression(n_jobs=-1)),\r\n",
    "        (\"SVC\", SVC()),\r\n",
    "        (\"TREE\", DecisionTreeClassifier())\r\n",
    "    ]\r\n",
    "    \r\n",
    "    for name, model in models:\r\n",
    "        # Fit model\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        \r\n",
    "        # Predict on training- and testset\r\n",
    "        pred_train = model.predict(X_train)\r\n",
    "        pred_test = model.predict(X_test)\r\n",
    "        \r\n",
    "        # Calculate error rate\r\n",
    "        error_rate_train = (1.0 - accuracy_score(pred_train, y_train)) * 100\r\n",
    "        error_rate_test = (1.0 - accuracy_score(pred_test, y_test)) * 100\r\n",
    "        \r\n",
    "        # print results\r\n",
    "        print(\"{} train: {:.3f}%, test: {:.3f}%\".format(name, error_rate_train, error_rate_test))  \r\n",
    "        \r\n",
    "    print(\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using dataset: USPS\n",
      "GNB train: 24.126%, test: 28.052%\n",
      "KNN train: 2.085%, test: 5.531%\n",
      "LR train: 1.413%, test: 8.221%\n",
      "SVC train: 0.631%, test: 5.282%\n",
      "TREE train: 0.000%, test: 16.542%\n",
      "\n",
      "Using dataset: ARDIS\n",
      "GNB train: 56.939%, test: 61.800%\n",
      "KNN train: 4.439%, test: 8.600%\n",
      "LR train: 5.667%, test: 13.500%\n",
      "SVC train: 1.061%, test: 4.100%\n",
      "TREE train: 0.000%, test: 23.900%\n",
      "\n",
      "Using dataset: MNIST\n",
      "GNB train: 44.625%, test: 45.600%\n",
      "KNN train: 1.648%, test: 2.940%\n",
      "LR train: 7.455%, test: 7.570%\n",
      "SVC train: 1.208%, test: 2.010%\n",
      "TREE train: 0.000%, test: 11.040%\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}